---

title: Optimizers


keywords: fastai
sidebar: home_sidebar

summary: "Collection of usefull `Optimizers`"
description: "Collection of usefull `Optimizers`"
nb_path: "nbs/00c_core.optim.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/00c_core.optim.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Ranger</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Ranger" class="doc_header"><code>Ranger</code><a href="https://github.com/benihime91/lightning_cv/tree/master/lightning_cv/core/optim.py#L18" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Ranger</code>(<strong><code>params</code></strong>:<code>Iterable</code>[<code>T_co</code>], <strong><code>betas</code></strong>:<code>Tuple</code>[<code>float</code>, <code>float</code>]=<em><code>(0.95, 0.999)</code></em>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-05</code></em>, <strong><code>k</code></strong>:<code>int</code>=<em><code>6</code></em>, <strong><code>alpha</code></strong>:<code>float</code>=<em><code>0.5</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>weight_decay</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<p>Convenience method for <code>Lookahead</code> with <code>RAdam</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Ranger with Gradient Centralization</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="RangerGC" class="doc_header"><code>class</code> <code>RangerGC</code><a href="https://github.com/benihime91/lightning_cv/tree/master/lightning_cv/core/optim.py#L25" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>RangerGC</code>(<strong><code>params</code></strong>:<code>Iterable</code>[<code>T_co</code>], <strong><code>lr</code></strong>:<code>float</code>=<em><code>0.001</code></em>, <strong><code>alpha</code></strong>:<code>float</code>=<em><code>0.5</code></em>, <strong><code>k</code></strong>:<code>int</code>=<em><code>6</code></em>, <strong><code>N_sma_threshhold</code></strong>:<code>int</code>=<em><code>5</code></em>, <strong><code>betas</code></strong>:<code>Tuple</code>[<code>float</code>, <code>float</code>]=<em><code>(0.95, 0.999)</code></em>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-05</code></em>, <strong><code>weight_decay</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0</code></em>, <strong><code>use_gc</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>gc_conv_only</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <code>Optimizer</code></p>
</blockquote>
<p>Ranger deep learning optimizer - RAdam + Lookahead + Gradient Centralization, combined into one optimizer.
From - <a href="https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer/blob/master/ranger/ranger.py">https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer/blob/master/ranger/ranger.py</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>SGDP</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SGDP" class="doc_header"><code>class</code> <code>SGDP</code><a href="https://github.com/benihime91/lightning_cv/tree/master/lightning_cv/core/optim.py#L167" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SGDP</code>(<strong><code>params</code></strong>:<code>Iterable</code>[<code>T_co</code>], <strong><code>lr</code></strong>=<em><code>&lt;required parameter&gt;</code></em>, <strong><code>momentum</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0</code></em>, <strong><code>dampening</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0</code></em>, <strong><code>weight_decay</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0</code></em>, <strong><code>nesterov</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-08</code></em>, <strong><code>delta</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>wd_ratio</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0.1</code></em>) :: <code>Optimizer</code></p>
</blockquote>
<p>SGDP Optimizer Implementation copied from <a href="https://github.com/clovaai/AdamP/blob/master/adamp/sgdp.py">https://github.com/clovaai/AdamP/blob/master/adamp/sgdp.py</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>AdamP</strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AdamP" class="doc_header"><code>class</code> <code>AdamP</code><a href="https://github.com/benihime91/lightning_cv/tree/master/lightning_cv/core/optim.py#L250" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AdamP</code>(<strong><code>params</code></strong>:<code>Iterable</code>[<code>T_co</code>], <strong><code>lr</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0.001</code></em>, <strong><code>betas</code></strong>:<code>Tuple</code>[<code>float</code>, <code>float</code>]=<em><code>(0.9, 0.999)</code></em>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-08</code></em>, <strong><code>weight_decay</code></strong>:<code>Union</code>[<code>float</code>, <code>int</code>]=<em><code>0</code></em>, <strong><code>delta</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>wd_ratio</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>nesterov</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <code>Optimizer</code></p>
</blockquote>
<p>AdamP Optimizer Implementation copied from <a href="https://github.com/clovaai/AdamP/blob/master/adamp/adamp.py">https://github.com/clovaai/AdamP/blob/master/adamp/adamp.py</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>RMSpropTF from <code>timm</code></strong></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="RMSpropTF" class="doc_header"><code>class</code> <code>RMSpropTF</code><a href="timm/optim/rmsprop_tf.py#L14" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>RMSpropTF</code>(<strong><code>params</code></strong>, <strong><code>lr</code></strong>=<em><code>0.01</code></em>, <strong><code>alpha</code></strong>=<em><code>0.9</code></em>, <strong><code>eps</code></strong>=<em><code>1e-10</code></em>, <strong><code>weight_decay</code></strong>=<em><code>0</code></em>, <strong><code>momentum</code></strong>=<em><code>0.0</code></em>, <strong><code>centered</code></strong>=<em><code>False</code></em>, <strong><code>decoupled_decay</code></strong>=<em><code>False</code></em>, <strong><code>lr_in_momentum</code></strong>=<em><code>True</code></em>) :: <code>Optimizer</code></p>
</blockquote>
<p>Implements RMSprop algorithm (TensorFlow style epsilon)</p>
<p>NOTE: This is a direct cut-and-paste of PyTorch RMSprop with eps applied before sqrt
and a few other modifications to closer match Tensorflow for matching hyper-params.</p>
<p>Noteworthy changes include:</p>
<ol>
<li>Epsilon applied inside square-root</li>
<li>square_avg initialized to ones</li>
<li>LR scaling of update accumulated in momentum buffer</li>
</ol>
<p>Proposed by G. Hinton in his
<code>course &lt;http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf&gt;</code>_.</p>
<p>The centered version first appears in <code>Generating Sequences
With Recurrent Neural Networks &lt;https://arxiv.org/pdf/1308.0850v5.pdf&gt;</code>_.</p>
<p>Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-2)
    momentum (float, optional): momentum factor (default: 0)
    alpha (float, optional): smoothing (decay) constant (default: 0.9)
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-10)
    centered (bool, optional) : if <code>True</code>, compute the centered RMSProp,
        the gradient is normalized by an estimation of its variance
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
    decoupled_decay (bool, optional): decoupled weight decay as per <a href="https://arxiv.org/abs/1711.05101">https://arxiv.org/abs/1711.05101</a>
    lr_in_momentum (bool, optional): learning rate scaling is included in the momentum buffer
        update as per defaults in Tensorflow</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

