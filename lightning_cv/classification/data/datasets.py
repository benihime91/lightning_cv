# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01b_classification.data.datasets.ipynb (unless otherwise specified).

__all__ = ['logger', 'BaseClassificationDataset', 'ImageFolderDataset', 'ImageCsvDataset',
           'ClassificationDatasetCatalog', 'ClassificationDatasetOutput', 'create_dataset']

# Cell
import os
from abc import *
from typing import *
from omegaconf import DictConfig
import pandas as pd
from fastcore.all import store_attr, ifnone, delegates, Path

import torch
from torch.utils.data import Dataset
from torchvision.datasets.folder import make_dataset

from ...core.utils.data import IMG_EXTENSIONS
from ...core import default_logger, _DatasetCatalog, LOADER_REGISTERY
from .transforms import (
    ImageClassificationTransforms,
    create_transform,
    TransformOutput,
)

logger = default_logger()

# Cell
class BaseClassificationDataset(Dataset):
    "Base class for ImageClassification Dataset"

    def __init__(self, cfg: DictConfig):
        super(BaseClassificationDataset, self).__init__()
        # instantiate transformations from cfg
        obj: TransformOutput = create_transform(cfg)
        self._transforms = obj.TRANSFORMS
        self.loader = obj.LOADER

    @property
    def transforms(self):
        return self._transforms

    @transforms.setter
    def transforms(self, x: ImageClassificationTransforms):
        self._transforms = x

    @abstractmethod
    def __getitem__(self, x):
        raise NotImplementedError

    @abstractmethod
    def __len__(self, x):
        raise NotImplementedError

# Cell
class ImageFolderDataset(BaseClassificationDataset):
    "Create `Dataset` instance from `source` using `transforms`"

    def __init__(
        self,
        source: Union[str, Path],
        cfg: DictConfig,
        classes: Dict = None,
        test: bool = False,
    ):

        store_attr("source, test")

        if not self.test:
            self.classes = ifnone(classes, self._find_classes(self.source))
            samples = make_dataset(self.source, self.classes, IMG_EXTENSIONS, None)
            self.images = [s[0] for s in samples]
            self.targets = [s[1] for s in samples]
            logger.info(
                f"Found {len(self.images)} files belonging to {len(set(self.targets))} classes."
            )

        if self.test:
            samples = self.make_test(source)
            self.images = samples
            logger.info(f"Found {len(self.images)} files.")

        super(ImageFolderDataset, self).__init__(cfg=cfg)

    def _find_classes(self, dir: str) -> Tuple[List[str], Dict[str, int]]:
        "Finds the class folders in the dataset"
        classes = [d.name for d in os.scandir(dir) if d.is_dir()]
        classes.sort()
        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        return class_to_idx

    @staticmethod
    def has_file_allowed_extension(filename: str, extensions: Tuple[str, ...]) -> bool:
        """
        Checks if a file is an allowed extension.
        Args:
            filename (string): path to a file
            extensions (tuple of strings): extensions to consider (lowercase)
        Returns:
            bool: True if the filename ends with one of given extensions

        From : https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py
        """
        return filename.lower().endswith(extensions)

    @staticmethod
    def is_valid_file(x: str) -> bool:
        return ImageFolderDataset.has_file_allowed_extension(
            x, cast(Tuple[str, ...], IMG_EXTENSIONS)
        )

    @staticmethod
    def make_test(root: str):
        instances = []
        is_valid_file = cast(Callable[[str], bool], ImageFolderDataset.is_valid_file)
        for fname in os.listdir(root):
            path = os.path.join(root, fname)
            if is_valid_file(path):
                instances.append(path)
        return instances

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        image = self.images[index]
        image = self.loader(image)
        aug_im = self._transforms(image)
        if self.test:
            return aug_im
        else:
            label = self.targets[index]
            return aug_im, torch.tensor(label, dtype=torch.long)

# Cell
class ImageCsvDataset(BaseClassificationDataset):
    "Create `Dataset` instance from `csv` using `transforms`, `image_col` and `label_col`"

    @delegates(pd.read_csv)
    def __init__(
        self,
        csv: str,
        image_col: str,
        cfg: DictConfig,
        label_col: Optional[str] = None,
        test: bool = False,
        **kwargs
    ):

        store_attr("label_col, image_col, test")
        self.df = pd.read_csv(csv, **kwargs)
        super(ImageCsvDataset, self).__init__(cfg=cfg)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, index):
        image = self.df[self.image_col][index]
        image = self.loader(image)
        aug_im = self._transforms(image)

        if self.test:
            return aug_im
        if not self.test:
            label = self.df[self.label_col][index]
            label = torch.tensor(label, dtype=torch.long)
            return aug_im, label

# Cell
ClassificationDatasetCatalog = _DatasetCatalog()
ClassificationDatasetCatalog.__doc__ = (
    _DatasetCatalog.__doc__
    + """
    Methods:
    `lightning_cv.classification.data.datasets.ClassificationDatasetCatalog.register`
    `lightning_cv.classification.data.datasets.ClassificationDatasetCatalog.get`
"""
)

# Cell
class ClassificationDatasetOutput(NamedTuple):
    TRAIN: Union[BaseClassificationDataset, Dataset] = None
    VALID: Union[BaseClassificationDataset, Dataset, None] = None

# Cell
def create_dataset(cfg: DictConfig) -> ClassificationDatasetOutput:
    """
    Retrive a `BaseClassificationDataset` instance from ImageClassificationDatasetCatalog.

    > Note: This function retrives both the train and valid datasets from config. Ideally you want want both
    train and validation datsets but if you do not have a validation dataset, then set
    `DATASETS.VALID = None`
    """
    train_ds: BaseClassificationDataset = ClassificationDatasetCatalog.get(
        cfg.DATASETS.TRAIN, cfg=cfg.TRANSFORMS.TRAIN
    )

    if cfg.DATASETS.VALID is not None or cfg.DATASETS.VALID != " ":
        valid_ds: BaseClassificationDataset = ClassificationDatasetCatalog.get(
            cfg.DATASETS.VALID, cfg=cfg.TRANSFORMS.VALID
        )
    else:
        logger.warning("Validation Dataset not specified !")
        valid_ds = None

    return ClassificationDatasetOutput(TRAIN=train_ds, VALID=valid_ds)