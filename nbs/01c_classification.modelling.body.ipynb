{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp classification.modelling.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ayushman/Desktop/lightning_cv/nbs/data'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import *\n",
    "from nbdev.imports import Config as NbdevConfig\n",
    "\n",
    "nbdev_path = str(NbdevConfig().path(\"nbs_path\")/'data')\n",
    "nbdev_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Body for Image Classification\n",
    "> Convenince functions to prepare a Model for Vision applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import *\n",
    "import importlib\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import re\n",
    "from omegaconf import DictConfig\n",
    "from fastcore.all import use_kwargs_dict\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from lightning_cv.core.layers import *\n",
    "from lightning_cv.core.common import Registry\n",
    "from lightning_cv.core.layers import ActivationCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from omegaconf import OmegaConf\n",
    "from fastcore.all import *\n",
    "from lightning_cv.core.layers import Mish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _is_pool_type(l): \n",
    "    return re.search(r'Pool[123]d$', l.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "m = nn.Sequential(nn.AdaptiveAvgPool2d(5), nn.Linear(2,3), nn.Conv2d(2,3,1), nn.MaxPool3d(5))\n",
    "test_eq([bool(_is_pool_type(m_)) for m_ in m.children()], [True,False,False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the LightningCV library cuts a pretrained model at the pooling layer (Similar to the Fastai Library). This function helps detecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def has_pool_type(m):\n",
    "    \"Return `True` if `m` is a pooling layer or has one in its children\"\n",
    "    if _is_pool_type(m): return True\n",
    "    for l in m.children():\n",
    "        if has_pool_type(l): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(nn.AdaptiveAvgPool2d(5), nn.Linear(2,3), nn.Conv2d(2,3,1), nn.MaxPool3d(5))\n",
    "assert has_pool_type(m)\n",
    "test_eq([has_pool_type(m_) for m_ in m.children()], [True,False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_body(model: nn.Module, cut: Optional[Union[int, Callable]] = None):\n",
    "    \"Cut off the body of a `model` as determined by `cut`\"\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int):      \n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): \n",
    "        return cut(model)\n",
    "    else:\n",
    "        raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = nn.Sequential(nn.Conv2d(3,5,3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3,4))\n",
    "m = create_body(tst)\n",
    "test_eq(len(m), 2)\n",
    "\n",
    "m = create_body(tst, cut=3)\n",
    "test_eq(len(m), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "tst = timm.create_model(\"resnet18\", pretrained=False, num_classes=0, global_pool='')\n",
    "m = create_body(tst)\n",
    "test_eq(len(m), 8)\n",
    "\n",
    "m = create_body(tst, cut=-2)\n",
    "test_eq(len(m), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TimmCnnBody(nn.Module):\n",
    "    \"default `nn.Module` to create a body for vision applications from `timm`\"\n",
    "    \n",
    "    @use_kwargs_dict(keep=True, pretrained=False, num_classes=0, global_pool=\"\")\n",
    "    def __init__(self, model_name: str, cut=None, act_layer: str=None, **kwargs):\n",
    "        super(TimmCnnBody, self).__init__()\n",
    "        # for different activation funtions\n",
    "        # if act_layer is None then the default activations func will be used\n",
    "        if act_layer is not None:\n",
    "            act_layer = ActivationCatalog.get(act_layer)\n",
    "        \n",
    "        net = timm.create_model(model_name, act_layer=act_layer, **kwargs)\n",
    "        \n",
    "        # prepare body\n",
    "        self.net = create_body(net, cut)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.net(xb)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: DictConfig):\n",
    "        \"create from a `Omegaconf/ Hydra` config\"\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TimmCnnBody\" class=\"doc_header\"><code>class</code> <code>TimmCnnBody</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TimmCnnBody</code>(**`model_name`**:`str`, **`cut`**=*`None`*, **`act_layer`**:`str`=*`None`*, **`pretrained`**=*`False`*, **`num_classes`**=*`0`*, **`global_pool`**=*`''`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "default `nn.Module` to create a body for vision applications from `timm`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TimmCnnBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None, global_pool='', num_classes=0)\n",
    "tst = TimmCnnBody(model_name=\"resnet18\", cut=-2, act_layer=None, pretrained=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: You can use the `act_layer` argument to change the activation layer of the `CnnBody`. `act_layer` is a string which corresponds to an `obj` in the `ActivationCatalog`. If you are using an activation func that is not in the `ActivationCatalog` be sure to register the `obj`. Also timm requires that the activation func should have a `inplace` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish, global_pool='', num_classes=0)\n",
    "tst = TimmCnnBody(model_name=\"resnet18\", cut=-2, act_layer=\"Mish\", pretrained=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish, in_chans=1)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish, global_pool='', num_classes=0, in_chans=1)\n",
    "tst = TimmCnnBody(model_name=\"resnet18\", cut=-2, act_layer=\"Mish\", pretrained=True, in_chans=1)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 1, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_first_layer(m):\n",
    "    \"Access first layer of a model\"\n",
    "    c,p,n = m,None,None  # child, parent, name\n",
    "    for n in next(m.named_parameters())[0].split('.')[:-1]:\n",
    "        p,c=c,getattr(c,n)\n",
    "    return c,p,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _update_first_layer(model, n_in):\n",
    "    \"Change first layer based on number of input channels\"\n",
    "    if n_in == 3: return\n",
    "    first_layer, parent, name = _get_first_layer(model)\n",
    "    assert isinstance(first_layer, nn.Conv2d), f'Change of input channels only supported with Conv2d, found {first_layer.__class__.__name__}'\n",
    "    assert getattr(first_layer, 'in_channels') == 3, f'Unexpected number of input channels, found {getattr(first_layer, \"in_channels\")} while expecting 3'\n",
    "    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}\n",
    "    params['bias'] = getattr(first_layer, 'bias') is not None\n",
    "    params['in_channels'] = n_in\n",
    "    new_layer = nn.Conv2d(**params)\n",
    "    setattr(parent, name, new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TorchvisionBody(nn.Module):\n",
    "    \"default `nn.Module` to create a body for vision applications from `torchvision.models`\"\n",
    "    \n",
    "    def __init__(self, model_name: str, in_chans: int = 3, pretrained: bool = True, cut=None):\n",
    "        super(TorchvisionBody, self).__init__()\n",
    "        \n",
    "        module = importlib.import_module(f'torchvision.models')\n",
    "        model  = getattr(module, model_name)(pretrained=pretrained)\n",
    "        \n",
    "        _update_first_layer(model, n_in=in_chans)\n",
    "        self.net = create_body(model, cut)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.net(xb)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: DictConfig):\n",
    "        \"create from a `Omegaconf/ Hydra` config\"\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "m1 = TorchvisionBody(\"resnet18\", cut=-2)\n",
    "m2 = TorchvisionBody(\"resnet18\", cut=None, in_chans=3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1(i)\n",
    "    o2 = m2(i)\n",
    "\n",
    "test_eq(o1, o2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelBody Registery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ModelBody = Registry(\"CNN_Body\")\n",
    "ModelBody.register(TimmCnnBody)\n",
    "ModelBody.register(TorchvisionBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registry of CNN_Body:\n",
       "╒═════════════════╤════════════════════════════════════╕\n",
       "│ Names           │ Objects                            │\n",
       "╞═════════════════╪════════════════════════════════════╡\n",
       "│ TimmCnnBody     │ <class '__main__.TimmCnnBody'>     │\n",
       "├─────────────────┼────────────────────────────────────┤\n",
       "│ TorchvisionBody │ <class '__main__.TorchvisionBody'> │\n",
       "╘═════════════════╧════════════════════════════════════╛"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide-input\n",
    "ModelBody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_cnn_body(cfg: DictConfig) -> nn.Module:\n",
    "    \"instante an obj from ModelBody registery using lightning_cv config\"\n",
    "    body = ModelBody.get(cfg.MODEL.BODY.NAME)\n",
    "    body = body.from_config(cfg.MODEL.BODY.ARGUMENTS)\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: TimmCnnBody\n",
      "ARGUMENTS:\n",
      "  model_name: resnet18\n",
      "  cut: -2\n",
      "  act_layer: null\n",
      "  pretrained: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightning_cv.config import get_cfg\n",
    "\n",
    "cfg = get_cfg(strict=False)\n",
    "print(OmegaConf.to_yaml(cfg.MODEL.BODY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = create_cnn_body(cfg)\n",
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None, global_pool='', num_classes=0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a different activation\n",
    "cfg.MODEL.BODY.ARGUMENTS.act_layer = \"Mish\"\n",
    "\n",
    "tst = create_cnn_body(cfg)\n",
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish, global_pool='', num_classes=0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a torchvision models\n",
    "\n",
    "# First we need to update the config\n",
    "cfg.MODEL.BODY.NAME = \"TorchvisionBody\"\n",
    "\n",
    "arguments = dict(model_name=\"resnet18\", pretrained=True, in_chans=3, cut=None)\n",
    "OmegaConf.update(cfg.MODEL.BODY, key=\"ARGUMENTS\", value=arguments)\n",
    "\n",
    "tst = create_cnn_body(cfg)\n",
    "m1  = TorchvisionBody(\"resnet18\", pretrained=True, in_chans=3, cut=None)\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1(i)\n",
    "    o2 = tst(i)\n",
    "\n",
    "test_eq(o1, o2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: For `create_cnn_body` to work your `obj` must be registerd in the `ModelBody` registery and the `obj` must have a `from_config` `classmethod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 00a_core.common.ipynb.\n",
      "Converted 00b_core.data_utils.ipynb.\n",
      "Converted 00c_core.optim.ipynb.\n",
      "Converted 00d_core.schedules.ipynb.\n",
      "Converted 00e_core.layers.ipynb.\n",
      "Converted 01a_classification.data.transforms.ipynb.\n",
      "Converted 01b_classification.data.datasets.ipynb.\n",
      "Converted 01c_classification.modelling.body.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning_cv",
   "language": "python",
   "name": "lightning_cv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
