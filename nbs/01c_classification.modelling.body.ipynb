{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp classification.modelling.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ayushman/Desktop/lightning_cv/nbs/data'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import *\n",
    "from nbdev.imports import Config as NbdevConfig\n",
    "\n",
    "nbdev_path = str(NbdevConfig().path(\"nbs_path\")/'data')\n",
    "nbdev_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Body for Image Classification\n",
    "> Convenince functions to prepare a Model for Vision applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import *\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import re\n",
    "from omegaconf import DictConfig\n",
    "from fastcore.all import use_kwargs_dict\n",
    "\n",
    "from lightning_cv.core.layers import *\n",
    "from lightning_cv.core.common import Registry\n",
    "from lightning_cv.core.layers import ActivationCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from omegaconf import OmegaConf\n",
    "from fastcore.all import *\n",
    "from lightning_cv.core.layers import Mish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _is_pool_type(l): \n",
    "    return re.search(r'Pool[123]d$', l.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "m = nn.Sequential(nn.AdaptiveAvgPool2d(5), nn.Linear(2,3), nn.Conv2d(2,3,1), nn.MaxPool3d(5))\n",
    "test_eq([bool(_is_pool_type(m_)) for m_ in m.children()], [True,False,False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the LightningCV library cuts a pretrained model at the pooling layer (Similar to the Fastai Library). This function helps detecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def has_pool_type(m):\n",
    "    \"Return `True` if `m` is a pooling layer or has one in its children\"\n",
    "    if _is_pool_type(m): return True\n",
    "    for l in m.children():\n",
    "        if has_pool_type(l): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(nn.AdaptiveAvgPool2d(5), nn.Linear(2,3), nn.Conv2d(2,3,1), nn.MaxPool3d(5))\n",
    "assert has_pool_type(m)\n",
    "test_eq([has_pool_type(m_) for m_ in m.children()], [True,False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_body(model: nn.Module, cut: Optional[Union[int, Callable]] = None):\n",
    "    \"Cut off the body of a `model` as determined by `cut`\"\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int):      \n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): \n",
    "        return cut(model)\n",
    "    else:\n",
    "        raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = nn.Sequential(nn.Conv2d(3,5,3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3,4))\n",
    "m = create_body(tst)\n",
    "test_eq(len(m), 2)\n",
    "\n",
    "m = create_body(tst, cut=3)\n",
    "test_eq(len(m), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "tst = timm.create_model(\"resnet18\", pretrained=False, num_classes=0, global_pool='')\n",
    "m = create_body(tst)\n",
    "test_eq(len(m), 8)\n",
    "\n",
    "m = create_body(tst, cut=-2)\n",
    "test_eq(len(m), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CnnBody(nn.Module):\n",
    "    \"default `nn.Module` to create a body for vision applications from `timm`\"\n",
    "    \n",
    "    @use_kwargs_dict(keep=True, pretrained=False, num_classes=0, global_pool=\"\")\n",
    "    def __init__(self, model_name: str, cut=None, act_layer: str=None, **kwargs):\n",
    "        super(CnnBody, self).__init__()\n",
    "        # for different activation funtions\n",
    "        # if act_layer is None then the default activations func will be used\n",
    "        if act_layer is not None:\n",
    "            act_layer = ActivationCatalog.get(act_layer)\n",
    "        \n",
    "        net = timm.create_model(model_name, act_layer=act_layer, **kwargs)\n",
    "        self._cfg = net.default_cfg\n",
    "        \n",
    "        # prepare body\n",
    "        self.net = create_body(net, cut)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.net(xb)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: DictConfig):\n",
    "        \"create from a `Omegaconf/ Hydra` config\"\n",
    "        return cls(**config)\n",
    "    \n",
    "    @property\n",
    "    def default_cfg(self):\n",
    "        # this default_cfg is usefull incase you want to use TestTimePool from timm\n",
    "        return self._cfg\n",
    "    \n",
    "    @default_cfg.setter\n",
    "    def default_cfg(self, x: Dict):\n",
    "        self._cfg = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CnnBody\" class=\"doc_header\"><code>class</code> <code>CnnBody</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CnnBody</code>(**`model_name`**:`str`, **`cut`**=*`None`*, **`act_layer`**:`str`=*`None`*, **`pretrained`**=*`False`*, **`num_classes`**=*`0`*, **`global_pool`**=*`''`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "default `nn.Module` to create a body for vision applications from `timm`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CnnBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None, global_pool='', num_classes=0)\n",
    "tst = CnnBody(model_name=\"resnet18\", cut=-2, act_layer=None, pretrained=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)\n",
    "test_eq(m1.default_cfg, tst.default_cfg)\n",
    "test_eq(m2.default_cfg, tst.default_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: You can use the `act_layer` argument to change the activation layer of the `CnnBody`. `act_layer` is a string which corresponds to an `obj` in the `ActivationCatalog`. If you are using an activation func that is not in the `ActivationCatalog` be sure to register the `obj`. Also timm requires that the activation func should have a `inplace` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish, global_pool='', num_classes=0)\n",
    "tst = CnnBody(model_name=\"resnet18\", cut=-2, act_layer=\"Mish\", pretrained=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)\n",
    "test_eq(m1.default_cfg, tst.default_cfg)\n",
    "test_eq(m2.default_cfg, tst.default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CnnBody(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Mish()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Mish()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Mish()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelBody Registery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ModelBody = Registry(\"CNN_Body\")\n",
    "ModelBody.register(CnnBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registry of CNN_Body:\n",
       "╒═════════╤════════════════════════════╕\n",
       "│ Names   │ Objects                    │\n",
       "╞═════════╪════════════════════════════╡\n",
       "│ CnnBody │ <class '__main__.CnnBody'> │\n",
       "╘═════════╧════════════════════════════╛"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide-input\n",
    "ModelBody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_cnn_body(cfg: DictConfig) -> nn.Module:\n",
    "    \"instante an obj from ModelBody registery using lightning_cv config\"\n",
    "    body = ModelBody.get(cfg.MODEL.BODY.NAME)\n",
    "    body = body.from_config(cfg.MODEL.BODY.ARGUMENTS)\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: CnnBody\n",
      "ARGUMENTS:\n",
      "  model_name: resnet18\n",
      "  cut: -2\n",
      "  act_layer: null\n",
      "  pretrained: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightning_cv.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "print(OmegaConf.to_yaml(cfg.MODEL.BODY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = create_cnn_body(cfg)\n",
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=None, global_pool='', num_classes=0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)\n",
    "test_eq(m1.default_cfg, tst.default_cfg)\n",
    "test_eq(m2.default_cfg, tst.default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a different activation\n",
    "cfg.MODEL.BODY.ARGUMENTS.act_layer = \"Mish\"\n",
    "tst = create_cnn_body(cfg)\n",
    "m1  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish)\n",
    "m2  = timm.create_model(\"resnet18\", pretrained=True, act_layer=Mish, global_pool='', num_classes=0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    i  = torch.randn(2, 3, 299, 299)\n",
    "    o1 = m1.forward_features(i)\n",
    "    o2 = m2(i)\n",
    "    o3 = tst(i)\n",
    "\n",
    "test_eq(o1, o3)\n",
    "test_eq(o2, o3)\n",
    "test_eq(m1.default_cfg, tst.default_cfg)\n",
    "test_eq(m2.default_cfg, tst.default_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: For `create_cnn_body` to work your `obj` must be registerd in the `ModelBody` registery and the `obj` must have a `from_config` `classmethod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 00a_core.common.ipynb.\n",
      "Converted 00b_core.data_utils.ipynb.\n",
      "Converted 00c_core.optim.ipynb.\n",
      "Converted 00d_core.schedules.ipynb.\n",
      "Converted 00e_core.layers.ipynb.\n",
      "Converted 01a_classification.data.transforms.ipynb.\n",
      "Converted 01b_classification.data.datasets.ipynb.\n",
      "Converted 01c_classification.modelling.body.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning_cv",
   "language": "python",
   "name": "lightning_cv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
