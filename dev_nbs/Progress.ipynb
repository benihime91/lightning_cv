{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "lesbian-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import Accuracy, F1, FBeta\n",
    "\n",
    "import time\n",
    "from typing import *\n",
    "\n",
    "import IPython.display as disp\n",
    "from pytorch_lightning.callbacks import ProgressBarBase, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "hybrid-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.common.param_scheduler import CosineParamScheduler, ParamScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "official-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRMultiplier(torch.optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"\n",
    "    A LRScheduler which uses fvcore :class:`ParamScheduler` to multiply the\n",
    "    learning rate of each param in the optimizer.\n",
    "    Every step, the learning rate of each parameter becomes its initial value\n",
    "    multiplied by the output of the given :class:`ParamScheduler`.\n",
    "    The absolute learning rate value of each parameter can be different.\n",
    "    This scheduler can be used as long as the relative scale among them do\n",
    "    not change during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer: torch.optim.Optimizer,\n",
    "                 multiplier: ParamScheduler,\n",
    "                 max_iter: int, last_iter: int = -1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer, last_iter: See ``torch.optim.lr_scheduler._LRScheduler``.\n",
    "                ``last_iter`` is the same as ``last_epoch``.\n",
    "            multiplier: a fvcore ParamScheduler that defines the multiplier on\n",
    "                every LR of the optimizer\n",
    "            max_iter: the total number of training iterations\n",
    "        \"\"\"\n",
    "        if not isinstance(multiplier, ParamScheduler):\n",
    "            raise ValueError(\n",
    "                \"_LRMultiplier(multiplier=) must be an instance of fvcore \"\n",
    "                f\"ParamScheduler. Got {multiplier} instead.\"\n",
    "            )\n",
    "        self._multiplier = multiplier\n",
    "        self._max_iter = max_iter\n",
    "        super().__init__(optimizer, last_epoch=last_iter)\n",
    "\n",
    "    def state_dict(self):\n",
    "        # fvcore schedulers are stateless. Only keep pytorch scheduler states\n",
    "        return {\"base_lrs\": self.base_lrs, \"last_epoch\": self.last_epoch}\n",
    "\n",
    "    def get_lr(self) -> List[float]:\n",
    "        multiplier = self._multiplier(self.last_epoch / self._max_iter)\n",
    "        return [base_lr * multiplier for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "effective-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST(os.getcwd(), train=True, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-bridge",
   "metadata": {},
   "source": [
    "# Fancy progress for Jupyter Notebooks\n",
    "> from : https://github.com/huggingface/transformers/blob/master/src/transformers/utils/notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "architectural-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    \"Format `t` (in seconds) to (h):mm:ss\"\n",
    "    t = int(t)\n",
    "    h, m, s = t // 3600, (t // 60) % 60, t % 60\n",
    "    return f\"{h}:{m:02d}:{s:02d}\" if h != 0 else f\"{m:02d}:{s:02d}\"\n",
    "\n",
    "\n",
    "def html_progress_bar(value, total, prefix, label, width=300):\n",
    "    # docstyle-ignore\n",
    "    return f\"\"\"\n",
    "    <div>\n",
    "        <style>\n",
    "            progress {{\n",
    "                border: none;\n",
    "                background-size: auto;\n",
    "            }}\n",
    "        </style>\n",
    "      {prefix}\n",
    "      <progress value='{value}' max='{total}' style='width:{width}px; height:20px; vertical-align: middle;'></progress>\n",
    "      {label}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def text_to_html_table(items):\n",
    "    \"Put the texts in `items` in an HTML table.\"\n",
    "    html_code = \"\"\"<table border=\"1\" class=\"dataframe\">\\n\"\"\"\n",
    "    html_code += \"\"\"  <thead>\\n    <tr style=\"text-align: left;\">\\n\"\"\"\n",
    "    for i in items[0]:\n",
    "        html_code += f\"      <th>{i}</th>\\n\"\n",
    "    html_code += \"    </tr>\\n  </thead>\\n  <tbody>\\n\"\n",
    "    for line in items[1:]:\n",
    "        html_code += \"    <tr>\\n\"\n",
    "        for elt in line:\n",
    "            elt = f\"{elt:.6f}\" if isinstance(elt, float) else str(elt)\n",
    "            html_code += f\"      <td>{elt}</td>\\n\"\n",
    "        html_code += \"    </tr>\\n\"\n",
    "    html_code += \"  </tbody>\\n</table><p>\"\n",
    "    return html_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "engaging-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookProgressBar:\n",
    "    \"\"\"\n",
    "    A progress par for display in a notebook.\n",
    "    Class attributes (overridden by derived classes)\n",
    "        - **warmup** (:obj:`int`) -- The number of iterations to do at the beginning while ignoring\n",
    "          :obj:`update_every`.\n",
    "        - **update_every** (:obj:`float`) -- Since calling the time takes some time, we only do it every presumed\n",
    "          :obj:`update_every` seconds. The progress bar uses the average time passed up until now to guess the next\n",
    "          value for which it will call the update.\n",
    "    Args:\n",
    "        total (:obj:`int`):\n",
    "            The total number of iterations to reach.\n",
    "        prefix (:obj:`str`, `optional`):\n",
    "            A prefix to add before the progress bar.\n",
    "        leave (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
    "            Whether or not to leave the progress bar once it's completed. You can always call the\n",
    "            :meth:`~transformers.utils.notebook.NotebookProgressBar.close` method to make the bar disappear.\n",
    "        parent (:class:`~transformers.notebook.NotebookTrainingTracker`, `optional`):\n",
    "            A parent object (like :class:`~transformers.utils.notebook.NotebookTrainingTracker`) that spawns progress\n",
    "            bars and handle their display. If set, the object passed must have a :obj:`display()` method.\n",
    "        width (:obj:`int`, `optional`, defaults to 300):\n",
    "            The width (in pixels) that the bar will take.\n",
    "    Example::\n",
    "        import time\n",
    "        pbar = NotebookProgressBar(100)\n",
    "        for val in range(100):\n",
    "            pbar.update(val)\n",
    "            time.sleep(0.07)\n",
    "        pbar.update(100)\n",
    "    \"\"\"\n",
    "\n",
    "    warmup = 5\n",
    "    update_every = 0.2\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        total: int,\n",
    "        prefix: Optional[str] = None,\n",
    "        leave: bool = True,\n",
    "        parent: Optional[\"NotebookTrainingTracker\"] = None,\n",
    "        width: int = 300,\n",
    "    ):\n",
    "        self.total = total\n",
    "        self.prefix = \"\" if prefix is None else prefix\n",
    "        self.leave = leave\n",
    "        self.parent = parent\n",
    "        self.width = width\n",
    "        self.last_value = None\n",
    "        self.comment = None\n",
    "        self.output = None\n",
    "\n",
    "    def update(self, value: int, force_update: bool = False, comment: str = None):\n",
    "        \"\"\"\n",
    "        The main method to update the progress bar to :obj:`value`.\n",
    "        Args:\n",
    "            value (:obj:`int`):\n",
    "                The value to use. Must be between 0 and :obj:`total`.\n",
    "            force_update (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
    "                Whether or not to force and update of the internal state and display (by default, the bar will wait for\n",
    "                :obj:`value` to reach the value it predicted corresponds to a time of more than the :obj:`update_every`\n",
    "                attribute since the last update to avoid adding boilerplate).\n",
    "            comment (:obj:`str`, `optional`):\n",
    "                A comment to add on the left of the progress bar.\n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "        if comment is not None:\n",
    "            self.comment = comment\n",
    "        if self.last_value is None:\n",
    "            self.start_time = self.last_time = time.time()\n",
    "            self.start_value = self.last_value = value\n",
    "            self.elapsed_time = self.predicted_remaining = None\n",
    "            self.first_calls = self.warmup\n",
    "            self.wait_for = 1\n",
    "            self.update_bar(value)\n",
    "        elif value <= self.last_value and not force_update:\n",
    "            return\n",
    "        elif force_update or self.first_calls > 0 or value >= min(self.last_value + self.wait_for, self.total):\n",
    "            if self.first_calls > 0:\n",
    "                self.first_calls -= 1\n",
    "            current_time = time.time()\n",
    "            self.elapsed_time = current_time - self.start_time\n",
    "            self.average_time_per_item = self.elapsed_time / (value - self.start_value)\n",
    "            if value >= self.total:\n",
    "                value = self.total\n",
    "                self.predicted_remaining = None\n",
    "                if not self.leave:\n",
    "                    self.close()\n",
    "            else:\n",
    "                self.predicted_remaining = self.average_time_per_item * (self.total - value)\n",
    "            self.update_bar(value)\n",
    "            self.last_value = value\n",
    "            self.last_time = current_time\n",
    "            self.wait_for = max(int(self.update_every / self.average_time_per_item), 1)\n",
    "\n",
    "    def update_bar(self, value, comment=None):\n",
    "        spaced_value = \" \" * (len(str(self.total)) - len(str(value))) + str(value)\n",
    "        if self.elapsed_time is None:\n",
    "            self.label = f\"[{spaced_value}/{self.total} : < :\"\n",
    "        elif self.predicted_remaining is None:\n",
    "            self.label = f\"[{spaced_value}/{self.total} {format_time(self.elapsed_time)}\"\n",
    "        else:\n",
    "            self.label = f\"[{spaced_value}/{self.total} {format_time(self.elapsed_time)} < {format_time(self.predicted_remaining)}\"\n",
    "            self.label += f\", {1/self.average_time_per_item:.2f} it/s\"\n",
    "        self.label += \"]\" if self.comment is None or len(self.comment) == 0 else f\", {self.comment}]\"\n",
    "        self.display()\n",
    "\n",
    "    def display(self):\n",
    "        self.html_code = html_progress_bar(self.value, self.total, self.prefix, self.label, self.width)\n",
    "        if self.parent is not None:\n",
    "            # If this is a child bar, the parent will take care of the display.\n",
    "            self.parent.display()\n",
    "            return\n",
    "        if self.output is None:\n",
    "            self.output = disp.display(disp.HTML(self.html_code), display_id=True)\n",
    "        else:\n",
    "            self.output.update(disp.HTML(self.html_code))\n",
    "\n",
    "    def close(self):\n",
    "        \"Closes the progress bar.\"\n",
    "        if self.parent is None and self.output is not None:\n",
    "            self.output.update(disp.HTML(\"\"))\n",
    "\n",
    "\n",
    "class NotebookTrainingTracker(NotebookProgressBar):\n",
    "    \"\"\"\n",
    "    An object tracking the updates of an ongoing training with progress bars and a nice table reporting metrics.\n",
    "    Args:\n",
    "        num_steps (:obj:`int`): The number of steps during training.\n",
    "        column_names (:obj:`List[str]`, `optional`):\n",
    "            The list of column names for the metrics table (will be inferred from the first call to\n",
    "            :meth:`~transformers.utils.notebook.NotebookTrainingTracker.write_line` if not set).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_steps, column_names=None, prefix=\"\"):\n",
    "        super().__init__(num_steps)\n",
    "        self.inner_table = None if column_names is None else [column_names]\n",
    "        self.child_bar = None\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self):\n",
    "        self.html_code = html_progress_bar(self.value, self.total, self.prefix, self.label, self.width)\n",
    "        if self.inner_table is not None:\n",
    "            self.html_code += text_to_html_table(self.inner_table)\n",
    "        if self.child_bar is not None:\n",
    "            self.html_code += self.child_bar.html_code\n",
    "        if self.output is None:\n",
    "            self.output = disp.display(disp.HTML(self.html_code), display_id=True)\n",
    "        else:\n",
    "            self.output.update(disp.HTML(self.html_code))\n",
    "\n",
    "    def write_line(self, values):\n",
    "        \"\"\"\n",
    "        Write the values in the inner table.\n",
    "        Args:\n",
    "            values (:obj:`Dict[str, float]`): The values to display.\n",
    "        \"\"\"\n",
    "        if self.inner_table is None:\n",
    "            self.inner_table = [list(values.keys()), list(values.values())]\n",
    "        else:\n",
    "            columns = self.inner_table[0]\n",
    "            if len(self.inner_table) == 1:\n",
    "                # We give a chance to update the column names at the first iteration\n",
    "                for key in values.keys():\n",
    "                    if key not in columns:\n",
    "                        columns.append(key)\n",
    "                self.inner_table[0] = columns\n",
    "            self.inner_table.append([values[c] for c in columns])\n",
    "\n",
    "    def add_child(self, total, prefix=None, width=300):\n",
    "        \"\"\"\n",
    "        Add a child progress bar displayed under the table of metrics. The child progress bar is returned (so it can be\n",
    "        easily updated).\n",
    "        Args:\n",
    "            total (:obj:`int`): The number of iterations for the child progress bar.\n",
    "            prefix (:obj:`str`, `optional`): A prefix to write on the left of the progress bar.\n",
    "            width (:obj:`int`, `optional`, defaults to 300): The width (in pixels) of the progress bar.\n",
    "        \"\"\"\n",
    "        self.child_bar = NotebookProgressBar(total, prefix=prefix, parent=self, width=width)\n",
    "        return self.child_bar\n",
    "\n",
    "    def remove_child(self):\n",
    "        \"\"\"\n",
    "        Closes the child progress bar.\n",
    "        \"\"\"\n",
    "        self.child_bar = None\n",
    "        self.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "emotional-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookProgressCallback(ProgressBarBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._force_next_update = False\n",
    "        self.training_tracker = None\n",
    "        self.prediction_bar = None\n",
    "\n",
    "    def on_sanity_check_start(self, trainer, pl_module):\n",
    "        super().on_sanity_check_start(trainer, pl_module)\n",
    "        # dummy progress bar\n",
    "        self.prediction_bar = NotebookProgressBar(int(trainer.num_sanity_val_steps), prefix=\"Validation sanity check\")\n",
    "\n",
    "    def on_sanity_check_end(self, trainer, pl_module):\n",
    "        super().on_sanity_check_end(trainer, pl_module)\n",
    "        # remove bars\n",
    "        self.prediction_bar.update(1)\n",
    "        self.prediction_bar.close()\n",
    "        self.training_tracker = None\n",
    "        self.prediction_bar   = None\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        super().on_train_start(trainer, pl_module)\n",
    "        self.first_column = \"Epoch\"\n",
    "        steps = trainer.max_steps or int(self.total_train_batches * trainer.max_epochs)\n",
    "        self.training_tracker = NotebookTrainingTracker(steps, prefix=\"Training\")\n",
    "        \n",
    "    def on_epoch_start(self, trainer, pl_module):\n",
    "        super().on_epoch_start(trainer, pl_module)\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _format_prog_bar_dict(progbar_dict: dict):\n",
    "        vals = {}\n",
    "        for k, v in progbar_dict.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = round(v.data.cpu().numpy().item(), 4)\n",
    "            elif isinstance(v, str):\n",
    "                pass\n",
    "            else:\n",
    "                v = round(v, 3)\n",
    "            vals[k] = v\n",
    "        return vals \n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx, dataloader_idx)\n",
    "        epoch = int(trainer.current_epoch)\n",
    "        prog_dict = self._format_prog_bar_dict(trainer.progress_bar_dict)\n",
    "        self.training_tracker.update(\n",
    "            trainer.global_step + 1, \n",
    "            comment=f\"Epoch {trainer.current_epoch} {prog_dict}\", \n",
    "            force_update=self._force_next_update,)\n",
    "        self._force_next_update = False\n",
    "\n",
    "    def on_validation_start(self, trainer, pl_module):\n",
    "        super().on_validation_start(trainer, pl_module)\n",
    "        if not trainer.running_sanity_check:\n",
    "            if self.prediction_bar is None:\n",
    "                if self.training_tracker is not None:\n",
    "                    self.prediction_bar = self.training_tracker.add_child(self.total_val_batches, prefix=\"Validating\")\n",
    "        self.prediction_bar.update(1)\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        super().on_validation_batch_end(trainer, pl_module, outputs, batch, batch_idx, dataloader_idx)\n",
    "        self.prediction_bar.update(self.prediction_bar.value + 1)\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        super().on_validation_end(trainer, pl_module)\n",
    "        total_train_batches = self.total_train_batches\n",
    "        metrics = trainer.callback_metrics\n",
    "        values  = {}\n",
    "        values[\"Epoch\"] = trainer.current_epoch\n",
    "\n",
    "        if self.training_tracker is not None:\n",
    "            for k, v in metrics.items():\n",
    "                splits = k.split(\"_\")\n",
    "                name = \" \".join([part.capitalize() for part in splits])\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    values[name] = v.data.cpu().numpy().item()\n",
    "                else:\n",
    "                    values[name] = v\n",
    "            \n",
    "            if total_train_batches != float('inf'):\n",
    "                # Measure speed performance metrics.\n",
    "                runtime = time.time() - self.start_time  # seconds\n",
    "                total_val_batches   = self.total_val_batches\n",
    "                n_obs = total_train_batches + total_val_batches\n",
    "                samples_per_second = 1 / (runtime / n_obs)    \n",
    "\n",
    "                values[\"Time\"] = round(runtime, 4)\n",
    "                values[\"Samples /s\"] = round(samples_per_second, 4)\n",
    "\n",
    "            self.training_tracker.write_line(values)\n",
    "            self.training_tracker.remove_child()\n",
    "            self.prediction_bar = None\n",
    "            self._force_next_update = True\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        super().on_train_end(trainer, pl_module)\n",
    "        self.training_tracker.update(trainer.global_step, force_update=True)\n",
    "        self.training_tracker = None\n",
    "\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        super().on_test_start(trainer, pl_module)\n",
    "        \n",
    "        self.test_progress_bar = NotebookProgressBar(int(self.total_test_batches), prefix=\"Testing\")\n",
    "        self.test_progress_bar.update(1)\n",
    "\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        super().on_test_batch_end(trainer, pl_module,outputs, batch, batch_idx, dataloader_idx)\n",
    "        self.test_progress_bar.update(self.test_progress_bar.value + 1)\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        super().on_test_end(trainer, pl_module)\n",
    "        self.test_progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-syndication",
   "metadata": {},
   "source": [
    "# Tests -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "inner-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        layers = [\n",
    "            torch.nn.Conv2d(1, 10, 5, stride=1, padding=0), # output: nx10x24x24\n",
    "            torch.nn.AvgPool2d(kernel_size=3, stride=2, padding=0), # output: nx10x11x11\n",
    "            torch.nn.ReLU(inplace=True), # output: nx10x11x11\n",
    "            torch.nn.Conv2d(10, 20, 5, stride=1, padding=0), # output: nx20x7x7\n",
    "            torch.nn.AvgPool2d(kernel_size=3, stride=2, padding=0), # output: nx20x3x3\n",
    "            torch.nn.ReLU(inplace=True), # output: nx20x3x3\n",
    "            torch.nn.Flatten(), # output: nx180\n",
    "            torch.nn.Dropout(0.3), # output: nx180\n",
    "            torch.nn.Linear(180, out_features=512, bias=True), # output: nx512\n",
    "            torch.nn.ReLU(inplace=True), # output: nx512\n",
    "            torch.nn.Linear(512, out_features=10, bias=False), # output: nx10\n",
    "        ]\n",
    "        \n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # metrics\n",
    "        self.train_metric = Accuracy()\n",
    "        self.valid_metric = Accuracy()\n",
    "        self.valid_f1_score = F1(num_classes=self.hparams.classes)\n",
    "        self.valid_fbeta_score = FBeta(num_classes=self.hparams.classes)\n",
    "        self.test_f1_score = F1(num_classes=self.hparams.classes)\n",
    "        self.test_fbeta_score = FBeta(num_classes=self.hparams.classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y  = batch\n",
    "        y_hat = self(x)\n",
    "        loss  = self.criterion(y_hat, y)\n",
    "        accuracy = self.train_metric(y_hat, y)\n",
    "        \n",
    "        # log values\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=False)\n",
    "        self.log(\"train_accuracy\", accuracy, on_step=True, prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y  = batch\n",
    "        y_hat = self(x)\n",
    "        loss  = self.criterion(y_hat, y)\n",
    "        \n",
    "        # compute metrics\n",
    "        accuracy = self.valid_metric(y_hat, y)\n",
    "        f1 = self.valid_f1_score(y_hat, y)\n",
    "        fbeta = self.valid_fbeta_score(y_hat, y)\n",
    "        \n",
    "        # log values\n",
    "        self.log(\"valid_loss\", loss)\n",
    "        self.log(\"valid_accuracy\", accuracy)\n",
    "        self.log(\"valid_f1\", f1)\n",
    "        self.log(\"valid_fbeta\", fbeta)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y  = batch\n",
    "        y_hat = self(x)\n",
    "        loss  = self.criterion(y_hat, y)\n",
    "        \n",
    "        # compute metrics\n",
    "        accuracy = self.valid_metric(y_hat, y)\n",
    "        f1 = self.test_f1_score(y_hat, y)\n",
    "        fbeta = self.test_fbeta_score(y_hat, y)\n",
    "        \n",
    "        # log values\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_accuracy\", accuracy)\n",
    "        self.log(\"test_f1\", f1)\n",
    "        self.log(\"test_fbeta\", fbeta)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        num_training_samples = len(self.train_dataloader()) or len(self.datamodule.train_dataloader())\n",
    "        iters = self.trainer.max_steps or (self.trainer.max_epochs * num_training_samples)\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = LRMultiplier(opt, CosineParamScheduler(1e-02, 1e-05), max_iter=iters)\n",
    "        sch = dict(scheduler=scheduler, interval='step', name=\"LearningRate\")\n",
    "        return [opt], [sch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cordless-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | network           | Sequential       | 103 K \n",
      "1 | criterion         | CrossEntropyLoss | 0     \n",
      "2 | train_metric      | Accuracy         | 0     \n",
      "3 | valid_metric      | Accuracy         | 0     \n",
      "4 | valid_f1_score    | F1               | 0     \n",
      "5 | valid_fbeta_score | FBeta            | 0     \n",
      "6 | test_f1_score     | F1               | 0     \n",
      "7 | test_fbeta_score  | FBeta            | 0     \n",
      "-------------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            progress {\n",
       "                border: none;\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      Training\n",
       "      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5625/5625 01:26, Epoch 2 {'loss': '1.19', 'v_num': 2}]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Valid Loss</th>\n",
       "      <th>Valid Accuracy</th>\n",
       "      <th>Valid F1</th>\n",
       "      <th>Valid Fbeta</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Time</th>\n",
       "      <th>Samples /s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.731360</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>1.853559</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>29.433200</td>\n",
       "      <td>127.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.194513</td>\n",
       "      <td>0.738733</td>\n",
       "      <td>0.738733</td>\n",
       "      <td>0.738733</td>\n",
       "      <td>1.284791</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>28.640200</td>\n",
       "      <td>130.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.137736</td>\n",
       "      <td>0.743683</td>\n",
       "      <td>0.743683</td>\n",
       "      <td>0.743683</td>\n",
       "      <td>1.272945</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>29.570400</td>\n",
       "      <td>126.816100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "mnist_train = MNIST(os.getcwd(), train=True, download=False, transform=transforms.ToTensor())\n",
    "mnist_train = DataLoader(mnist_train, batch_size=32, num_workers=4)\n",
    "mnist_val   = MNIST(os.getcwd(), train=True, download=False, transform=transforms.ToTensor())\n",
    "mnist_val   = DataLoader(mnist_val, batch_size=32, num_workers=4)\n",
    "\n",
    "task = CoolSystem()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=3, \n",
    "    callbacks=[NotebookProgressCallback(), pl.callbacks.LearningRateMonitor(\"step\")])\n",
    "\n",
    "trainer.fit(task, mnist_train, mnist_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning_cv",
   "language": "python",
   "name": "lightning_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
